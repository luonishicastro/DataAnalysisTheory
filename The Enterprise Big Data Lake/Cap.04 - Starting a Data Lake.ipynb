{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>What is the best way ofp reventing proliferation of Data Puddles?</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>By building a centralized Data Lake. Then, when business teams decide that they need Hadoop, the compute resources and the data for their projects are already available in the data lake. By providing managed compute resources with preloaded data, yet giving users autonomy through self-service, an enterprise data lake gives business the best of both worlds: support for the components that are difficult for them to maintain and feedom from waiting for IT before working on their projects.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Describe the main approaches for starting new Data Lakes.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>For companies trying to introduce big data, there are a few popular approaches:\n",
    "\n",
    "* Start by offloading some existing functions in Hadoop and then add more data and expand into a data lake.\n",
    "* Start with a data science initiative, show great ROI, and the expand it to a full data lake.\n",
    "* Build the data lake from scratch as a central point of governance.\n",
    "</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>What are the best ways to bring data science into a organization?</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Firstly, by finding a visible problem that: (a) is well defined and well understood; (b) can show quick, measurable benefits; (c) can be solved through machine learning or advanced analytics; (d) requires data that the team can easily procure; (e) would be very difficult or time consuming to solve without applying data science techniques.\n",
    "<br>\n",
    "For the third requirement, it is often possible to identify a good candidate in two ways: by searching industry sites and publications for other companies that have solved similar problems using machine learning, or by hiring experienced consultants who can recommend which of those problems lend themselves to machine learning or advanced analytics.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Give some data science driven projects examples.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>As distinguished by different vericals:\n",
    "* Financial services: Governance, risk management, and compliance (GRC), including portfolio risk analysis and ensuring compliance with a myriad of regulations; fraud detection; branch location optimization; automated trading;\n",
    "* Healthcare: Governance and compliance, medical research, patient care analytics, IoT medical devices, wereable devices, remote healthcare;\n",
    "* Pharmaceutics: Genome research, process manufacturing optimization;\n",
    "* Manufacturing: collecting IoT device information, quality control, preventive maintenance, Industry 4.0;\n",
    "* Education: Adminissions, student success;\n",
    "* Retail: price optmization, purchase recommendations, propensity to buy;\n",
    "* Adtech: automated bidding, exchanges;\n",
    "</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Provide some considerations on building large Data Lakes;</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>(1) Have a pipeline of very promising data science projects that you will be able to execute as you are building up the data lake to keep showing value. Ideally, make sure that you can demonstrate one valuable insight per quarter for the duration of the data lake construction; (2) Broaden the data lake beyond the original data science use cases as soon as possible by moving other workloads into the lake, from operational jobs like ETL to governance to simple BI and reporting; (3) Don't try to boil the ocean right away. Keep building up the cluster and adding data sources as you keep showing more value; (4) Focus on getting additional departments, teams, and projects to use the data lake.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Detail the approaches to initiate Big Data.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Strategy 1: Offload Existing Functionality\n",
    "</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Because of the size of a data warehouse only increases, and IT budgets often include the cost of expansion, it is very attractive to offload some processing from a data warehouse instead of growing the data warehouse.\n",
    "<br>\n",
    "The most common processing task to offload to a big data system is the T part of ETL. With big data systems, it is possible to do the transformation step in a big data framework and then loading data into the data warehouse.\n",
    "Another common practice is to move the processing of non-tabular data to Hadoop. This way they can be handled efficiently, instead of requiring conversion to a relational format and uploading into a data warehouse.\n",
    "<br>\n",
    "A third class of processing that's commonly moved to big data platforms is real-time or streaming processing. \n",
    "</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Strategy 2: Data Lakes for New Projects\n",
    "</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Instead of offloading existing functionality</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Enumerate some of the steps IT Teams go through after transforming the automated processing to big data frameworks.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>\n",
    "* Add data that's not being processed by automated jobs to create a comprehensive data lake.\n",
    "* Provide data access\n",
    "</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Explain the basics on MapReduce.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>The idea of MapReduce is to break work into mappers that can run in parallel and reducers that take the output of mappers and process it. The first operation is called \"mapping\" because it takes each element of input data and maps a function onto int, leaving the output of the reducer to handle.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Explain the basics about the Hadoop File System.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>A special filesystem is needed to provide to provide data efficiently to MapReduce, and the most popular one is the Hadoop File System (HDFS). It is massively parallel, highly available, self-healing filesystem. Like many other NoSQL databases, HDFS is a sophisticated kind of key/value store.\n",
    "<br>\n",
    "It makes multiple copies of each block (by default, three copies) and stores these copies on different nodes. This way, if one node dies, two other copies are still available and the block will be copied to a third node once the failure is detected without affecting availability. The multiple copies also facilitate load balancing, because we can choose to send the work to the least busy node that contains the data.\n",
    "</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

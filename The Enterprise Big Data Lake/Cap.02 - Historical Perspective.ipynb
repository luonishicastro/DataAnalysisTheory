{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Describe the evolution of the data tools related to Databases.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><li><b>Spreadsheet:</b> the first step in the self-service data revolution wat the spreadsheet. It allowed nondevelopers to work with data directly. For the first time, the analysts were able to work with the data themselves and manipulate it into the shapes they desired. However, spreadsheets did not scale beyond small amounts of data and could address only a small subset of the problemas that analysts wanted to address.</li>\n",
    "<li><b>RDBM's:</b> meanwhile, companies began to realize that the data, not the applications, was the crown jewel. Data had to be carefully managed, checked for consistency, and backed up. Instead of each program having to develop these capabilities itself, they were extracted and provided by a new class of systems called database management systems.</li>\n",
    "    Relational database management systems allow the users to describe the data explicitly to the database. Users create a schema - a human readable collection of tables and fields. Instead of having to always go through the programs to get to the data, the users of RDMS's were able to query data directly. Eventually, a somewhat standard language called Structured Query Language (SQL) emerged and decame the lingua franca of databases.\n",
    "<li><b>Data Warehousing: </b> the idea was to completely separate data from applications and, in fact, to combine data from multiple applications in one system and use that system for analytics.</li></i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>What are the main characteristics of Data Warehouses?</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>The database is at the heart of a data warehouse. Usually, it is a relational database optimized for analytics-type processing: large, long queries; aggregation; and multitable joins. The database is usually heavily indexed and tuned to ensure optimal performance for the most common queries.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Define briefly the following concepts regarding Relational Databases.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>\n",
    "    <li><b>Normalization:</b> It is a way to break table into smaller ones in order to avoid repeating information;</li>\n",
    "    <li><b>Referential Integrity: </b> the correspondence between tables using primary (unique identifier) and foreign keys (reference to the primary keys);</li>\n",
    "    <li><b>Star Schema:</b> consists of a set of dimension and fact tables; The dimension tables represent the entities being analyzed; The fact table contains all the activities that involve the dimensions.</li>\n",
    "    <li><b>Slowly Changing Dimensions: </b> the goal is to keep track of a dimension entity's state over time, so that the transactions corresponding to the entity's state reflect that state over time, thus making analysis more accurate in a long term;</li>\n",
    "    <li><b>Massively Parallel Processing: </b> the alternative to usinng star schemas is to use a cluster os massively parallel computers that appear to the end user or BI tool as a single database;</li>\n",
    "    <li><b>Columnar Stores: </b> a columnar database store all the data for each column together instead of storing all the data for each row together;</li>\n",
    "    <li><b>Data Virtualization: </b> an alternative approach instead of integrating all data into a conforming schema, is to create a logical or virtual schema across multiple systems and then issue queries against that virtual schema.</li>\n",
    "</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>What is th main difference between ETL and ELT?</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>With ELT, the data gets loaded into the data warehouse as is and then converted into the right representation using the database engine. On the other hand, an ETL process extracts and tranform simultaneously, making all income data conform into a single format.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Explain the main characteristics of Data Quality Tools.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Data Quallity involves defining quality rules, applying those rules to data to detect violations - often called exceptions - and fixing those exeptions. Data quality rules comes in many shapes and sizes, but can generally br broken into several broad categories:\n",
    "* Scalar: applied to a specific value. For example, Name is a required fied and should have a value; Salary should be a number; Age should be between 0 and 150.\n",
    "* Field Level: applied to all values in a field. The most common examples have to do with field uniqueness (for example, Customer_ID should be unique) and field density (for example, Name cannot be empty);\n",
    "* Record Level: applied to all the fields in a single record. For example, we can specify that if the US_CITIZEN field is True then the Social_Seucirty_Number field should not be empty;\n",
    "* Data set (table/field) level: applied to the entire data set. These are not common and usually involve the number of records. For example, a data set containing sensor data should have at least one event per sensor per hour.\n",
    "* Cross-data set level: applied across data sets. Referential integrity rules are very common in relational systems. They basically state that a primary key should be unique and that a foreign key field should not have any value that does not exist in the primary key field.\n",
    "</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>What is Data Profiling?</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Is a technique of automatically gathering statistics about data to then ascertain its quality. Profiling tools usually read all the data and, for each field, keep track of how many values are of which type, how many values are empty, the minimum and maximum values, as well as the most frequent values for each field and some other statistics depending on the field.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>What are MDM Systems?</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Is a special class of data quality tool. It is used to create master lists of various entities (customers, products, suppliers etc); They are very sophisticated systems that take data from one or more systems, harmonize the data to a common schema and representation, and perform what's called entity resolution: finding multiple records that apply to the same entity.\n",
    "<br>\n",
    "Once the recods for the same entity have been identified, often it's found that they contain conflicting information. So, another task of the MDM system is to fix these conflicts, either automatically or by triggering a manual intervention, to create the golden record: the one correct record for an entity that everyone should use.\n",
    "</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Explain the main characteristics of Data Modeling Tools.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
